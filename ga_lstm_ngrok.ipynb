{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install deap\n",
        "!pip install bitstring\n",
        "!pip install pyngrok  # pyngrok installation\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import LSTM, Input, Dense\n",
        "from keras.models import Model\n",
        "from deap import base, creator, tools, algorithms\n",
        "from scipy.stats import bernoulli\n",
        "from bitstring import BitArray\n",
        "from matplotlib import pyplot as plt\n",
        "from pyngrok import ngrok  # Import from pyngrok\n",
        "\n",
        "# Function to import data from a CSV file\n",
        "def import_data(file_path):\n",
        "    \"\"\"\n",
        "    Imports data from a CSV file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the CSV file.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: DataFrame with selected data.\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(file_path, sep='\\t', encoding='latin1')\n",
        "    cols = df.columns[2:6]\n",
        "    return df[cols]\n",
        "\n",
        "# Function to prepare the dataset for the LSTM model\n",
        "def prepare_dataset(data, window_size, num_features):\n",
        "    \"\"\"\n",
        "    Prepares the data for use in the LSTM model.\n",
        "\n",
        "    Args:\n",
        "        data (pandas.DataFrame): DataFrame with input data.\n",
        "        window_size (int): Size of the window.\n",
        "        num_features (int): Number of features.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray, numpy.ndarray: Prepared training data (X, Y).\n",
        "    \"\"\"\n",
        "    # Validate the window size\n",
        "    if window_size <= 0:\n",
        "        print(\"Invalid value for window size:\", window_size)\n",
        "        return np.array([]), np.array([])  # Return empty arrays\n",
        "\n",
        "    X, Y = [], []\n",
        "    n_future = 1\n",
        "    # Create input-output pairs for training\n",
        "    for i in range(window_size, len(data) - n_future + 1):\n",
        "        X.append(data[i - window_size:i, :num_features])\n",
        "        Y.append(data[i + n_future - 1:i + n_future, 3])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "# Function to train and evaluate an individual\n",
        "def train_evaluate(individual, data):\n",
        "    \"\"\"\n",
        "    Trains and evaluates an individual using an LSTM model.\n",
        "\n",
        "    Args:\n",
        "        individual (list): Individual with hyperparameters.\n",
        "        data (numpy.ndarray): Training data.\n",
        "\n",
        "    Returns:\n",
        "        tuple: RMSE of the model.\n",
        "    \"\"\"\n",
        "    window_size_bits = BitArray(individual[:5])\n",
        "    num_units_bits = BitArray(individual[5:])\n",
        "    window_size = window_size_bits.uint\n",
        "    num_units = num_units_bits.uint\n",
        "    print('\\nWindow Size:', window_size, ', Num of Units:', num_units)\n",
        "\n",
        "    if window_size == 0:\n",
        "        print(\"Invalid value for window size:\", window_size)\n",
        "        window_size = 1\n",
        "\n",
        "    if num_units <= 0:\n",
        "        print(\"Invalid value for number of units, setting to default:\", num_units)\n",
        "        num_units = 1\n",
        "\n",
        "    X, Y = prepare_dataset(data, window_size, 4)\n",
        "    if len(X) == 0 or len(Y) == 0:\n",
        "        return 100.0,  # Return a high error value if the data is invalid\n",
        "\n",
        "    # Split the dataset into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.10, random_state=1120)\n",
        "\n",
        "    # Define the LSTM model\n",
        "    inputs = Input(shape=(window_size, 4))\n",
        "    x = LSTM(num_units, input_shape=(window_size, 4))(inputs)\n",
        "    predictions = Dense(1, activation='linear')(x)\n",
        "    model = Model(inputs=inputs, outputs=predictions)\n",
        "    print(model.summary())\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size=10, shuffle=True)\n",
        "\n",
        "    # Predict on the validation set\n",
        "    y_pred = model.predict(X_val)\n",
        "\n",
        "    # Calculate the RMSE\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "    print('Validation RMSE:', rmse, '\\n')\n",
        "    return rmse,\n",
        "\n",
        "# Function to define individuals and population for the genetic algorithm\n",
        "def define_individuals_and_population(population_size, gene_length, train_data):\n",
        "    \"\"\"\n",
        "    Defines individuals and population for the genetic algorithm.\n",
        "\n",
        "    Args:\n",
        "        population_size (int): Size of the population.\n",
        "        gene_length (int): Length of the gene.\n",
        "        train_data (numpy.ndarray): Training data.\n",
        "\n",
        "    Returns:\n",
        "        list, base.Toolbox: Initial population and toolbox.\n",
        "    \"\"\"\n",
        "    creator.create('FitnessMax', base.Fitness, weights=(-1.0,))\n",
        "    creator.create('Individual', list, fitness=creator.FitnessMax)\n",
        "    toolbox = base.Toolbox()\n",
        "    toolbox.register('binary', bernoulli.rvs, 0.5)\n",
        "    toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.binary, n=gene_length)\n",
        "    toolbox.register('population', tools.initRepeat, list, toolbox.individual)\n",
        "    toolbox.register('mate', tools.cxOrdered)\n",
        "    toolbox.register('mutate', tools.mutShuffleIndexes, indpb=0.6)\n",
        "    toolbox.register('select', tools.selRoulette)\n",
        "    toolbox.register('evaluate', train_evaluate, data=train_data)\n",
        "    return toolbox.population(n=population_size), toolbox\n",
        "\n",
        "# Function to run the genetic algorithm\n",
        "def run_genetic_algorithm(population, toolbox, num_generations):\n",
        "    \"\"\"\n",
        "    Runs the genetic algorithm to optimize hyperparameters.\n",
        "\n",
        "    Args:\n",
        "        population (list): Initial population.\n",
        "        toolbox (base.Toolbox): Genetic algorithm toolbox.\n",
        "        num_generations (int): Number of generations.\n",
        "\n",
        "    Returns:\n",
        "        list, dict: Final population and statistics.\n",
        "    \"\"\"\n",
        "    return algorithms.eaSimple(population, toolbox, cxpb=0.6, mutpb=0.4, ngen=num_generations, verbose=False)\n",
        "\n",
        "# Function to get the best solution from the population\n",
        "def get_best_solution(population):\n",
        "    \"\"\"\n",
        "    Gets the best solution from the population.\n",
        "\n",
        "    Args:\n",
        "        population (list): Population of individuals.\n",
        "\n",
        "    Returns:\n",
        "        int, int: Best window size and best number of units.\n",
        "    \"\"\"\n",
        "    best_individual = tools.selBest(population, k=1)[0]\n",
        "    window_size_bits = BitArray(best_individual[:5])\n",
        "    num_units_bits = BitArray(best_individual[5:])\n",
        "    best_window_size = window_size_bits.uint\n",
        "    best_num_units = num_units_bits.uint\n",
        "    return best_window_size, best_num_units\n",
        "\n",
        "# Function to implement the best solution and get real and predicted values\n",
        "def implement_best_solution(train_data, test_data, best_window_size, best_num_units, scaler):\n",
        "    \"\"\"\n",
        "    Implements the best solution found and gets real and predicted values.\n",
        "\n",
        "    Args:\n",
        "        train_data (numpy.ndarray): Training data.\n",
        "        test_data (numpy.ndarray): Test data.\n",
        "        best_window_size (int): Best window size.\n",
        "        best_num_units (int): Best number of LSTM units.\n",
        "        scaler (StandardScaler): Scaler used for the data.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray, numpy.ndarray, dict: Real values, predicted values, and training history.\n",
        "    \"\"\"\n",
        "    if best_window_size <= 0:\n",
        "        print(\"Invalid value for window size:\", best_window_size)\n",
        "        return np.array([]), np.array([]), {}  # Return empty arrays and an empty dictionary\n",
        "\n",
        "    num_features = 4\n",
        "    X_train, y_train = prepare_dataset(train_data, best_window_size, num_features)\n",
        "    X_test, y_test = prepare_dataset(test_data, best_window_size, num_features)\n",
        "\n",
        "    # Define the LSTM model\n",
        "    inputs = Input(shape=(best_window_size, num_features))\n",
        "    x = LSTM(best_num_units, input_shape=(best_window_size, num_features))(inputs)\n",
        "    predictions = Dense(1, activation='linear')(x)\n",
        "    model = Model(inputs=inputs, outputs=predictions)\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=5, batch_size=10, validation_split=0.1, verbose=1, shuffle=True)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate the RMSE\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "    # Inverse transform to get real values\n",
        "    y_test_real = scaler.inverse_transform(np.concatenate((np.zeros((y_test.shape[0], 3)), y_test), axis=1))[:, 3]\n",
        "    y_pred_real = scaler.inverse_transform(np.concatenate((np.zeros((y_pred.shape[0], 3)), y_pred), axis=1))[:, 3]\n",
        "\n",
        "    return y_test_real, y_pred_real, history.history\n",
        "\n",
        "# Function to setup ngrok and start tunnel\n",
        "def setup_ngrok(n_port):\n",
        "    \"\"\"\n",
        "    Sets up ngrok and starts a tunnel.\n",
        "\n",
        "    Args:\n",
        "        n_port (int): Port to expose.\n",
        "\n",
        "    Returns:\n",
        "        str: Public URL of the ngrok tunnel.\n",
        "    \"\"\"\n",
        "    # Configure ngrok token\n",
        "    token = \"2h1iUs3x1soTA6hsOCztzERJ18F_6NMsBSXyDC3n1HKCFP5fa\"\n",
        "    ngrok.set_auth_token(token)\n",
        "\n",
        "    # Start a tunnel for the specified port\n",
        "    public_url = ngrok.connect(n_port)\n",
        "    print(\"Public URL:\", public_url)\n",
        "    input(\"Press Enter to open the ngrok URL...\")\n",
        "    return public_url\n",
        "\n",
        "# Main function to run the entire process\n",
        "def MyModel():\n",
        "    global train_data\n",
        "    np.random.seed(1120)\n",
        "\n",
        "    # Setup ngrok and start tunnel\n",
        "    public_url = setup_ngrok(5000)\n",
        "\n",
        "    file_path = 'https://raw.githubusercontent.com/kevinmero/Unemployment-rate-prediction/main/data/desempleo.csv'\n",
        "\n",
        "    # Import the data\n",
        "    df_train = import_data(file_path)\n",
        "\n",
        "    # Split the data into training and test sets\n",
        "    train_data, test_data = train_test_split(df_train, test_size=0.10, random_state=42, shuffle=False)\n",
        "\n",
        "    # Scale the training data\n",
        "    scaler = StandardScaler()\n",
        "    train_data_scaled = scaler.fit_transform(train_data)\n",
        "\n",
        "    # Set parameters for the genetic algorithm\n",
        "    population_size = 4\n",
        "    num_generations = 4\n",
        "    gene_length = 9\n",
        "\n",
        "    # Run the genetic algorithm to find the best hyperparameters\n",
        "    population, toolbox = define_individuals_and_population(population_size, gene_length, train_data_scaled)\n",
        "    run_genetic_algorithm(population, toolbox, num_generations)\n",
        "\n",
        "    # Get the best solution found by the genetic algorithm\n",
        "    best_window_size, best_num_units = get_best_solution(population)\n",
        "\n",
        "    # Scale the test data using the same scaler\n",
        "    test_data_scaled = scaler.transform(test_data)\n",
        "\n",
        "    # Implement the best solution to get real and predicted values\n",
        "    real_values, predicted_values, history = implement_best_solution(train_data_scaled, test_data_scaled, best_window_size, best_num_units, scaler)\n",
        "\n",
        "    # Plot training and validation loss\n",
        "    plt.plot(history['loss'], label='Training loss')\n",
        "    plt.plot(history['val_loss'], label='Validation loss')\n",
        "    plt.legend()\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.show()\n",
        "\n",
        "    # Print real and predicted values\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"Real Values:\", real_values)\n",
        "    print(\"Predicted Values:\", predicted_values)\n",
        "    print(\"Best Window Size:\", best_window_size)\n",
        "    print(\"Best Num of Units:\", best_num_units)\n",
        "\n",
        "# Run the model\n",
        "MyModel()"
      ],
      "metadata": {
        "id": "Lual2kBaevuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VhfaxzXfewFs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}